{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib notebook\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag, pos_tag_sents\n",
    "from nltk.tag.perceptron import PerceptronTagger\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import wordnet as wn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "from math import *\n",
    "\n",
    "import nltk\n",
    "nltk.download(\"averaged_perceptron_tagger\")\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Data and Inital Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YPnkHADveVk-"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "215063"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drugs = pd.read_csv(\"train.tsv\",delimiter=\"\\t\")\n",
    "drugs_test = pd.read_csv(\"test.tsv\",delimiter=\"\\t\")\n",
    "split = len(drugs)\n",
    "drugs = pd.concat([drugs, drugs_test])\n",
    "len(drugs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FcwLGyVVeVlG"
   },
   "outputs": [],
   "source": [
    "# change first column name to \"id\"\n",
    "col = list(drugs.columns)\n",
    "col[0] = \"id\"\n",
    "drugs.columns = col\n",
    "\n",
    "# create positive, neutral, and negative categories for rating. 1-4 -> negative, 5-7 -> netural, 8-10 -> positive\n",
    "\n",
    "drugs[\"rating_categorized\"] = drugs.rating.apply(lambda x : 2 if x > 7 else (1 if (x > 4 and x <= 7) else 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "kDGnMhuZeVlL",
    "outputId": "21ce0141-cd12-4c7b-efb9-91f13b01ea8d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>drugName</th>\n",
       "      <th>condition</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>usefulCount</th>\n",
       "      <th>rating_categorized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14311</th>\n",
       "      <td>57701</td>\n",
       "      <td>Acetaminophen / hydrocodone</td>\n",
       "      <td>Pain</td>\n",
       "      <td>\"I suffered a .45 caliber GSW to the head in 2...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>June 26, 2015</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72301</th>\n",
       "      <td>168695</td>\n",
       "      <td>Vilazodone</td>\n",
       "      <td>Major Depressive Disorde</td>\n",
       "      <td>\"I started on Viibryd after having a DNA test ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>December 27, 2015</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23041</th>\n",
       "      <td>1607</td>\n",
       "      <td>Eluxadoline</td>\n",
       "      <td>Irritable Bowel Syndrome</td>\n",
       "      <td>\"Not covered by insurance\"</td>\n",
       "      <td>6.0</td>\n",
       "      <td>December 19, 2016</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36424</th>\n",
       "      <td>17559</td>\n",
       "      <td>Ethinyl estradiol / etonogestrel</td>\n",
       "      <td>Birth Control</td>\n",
       "      <td>\"I previously did a review on Nuva Ring about ...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>November 1, 2016</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133612</th>\n",
       "      <td>158793</td>\n",
       "      <td>Methylphenidate</td>\n",
       "      <td>ADHD</td>\n",
       "      <td>\"My son was prescribed the drug just before su...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>September 3, 2009</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                          drugName                 condition  \\\n",
       "14311    57701       Acetaminophen / hydrocodone                      Pain   \n",
       "72301   168695                        Vilazodone  Major Depressive Disorde   \n",
       "23041     1607                       Eluxadoline  Irritable Bowel Syndrome   \n",
       "36424    17559  Ethinyl estradiol / etonogestrel             Birth Control   \n",
       "133612  158793                   Methylphenidate                      ADHD   \n",
       "\n",
       "                                                   review  rating  \\\n",
       "14311   \"I suffered a .45 caliber GSW to the head in 2...     9.0   \n",
       "72301   \"I started on Viibryd after having a DNA test ...     1.0   \n",
       "23041                          \"Not covered by insurance\"     6.0   \n",
       "36424   \"I previously did a review on Nuva Ring about ...     8.0   \n",
       "133612  \"My son was prescribed the drug just before su...     6.0   \n",
       "\n",
       "                     date  usefulCount  rating_categorized  \n",
       "14311       June 26, 2015           10                   2  \n",
       "72301   December 27, 2015            1                   0  \n",
       "23041   December 19, 2016            0                   1  \n",
       "36424    November 1, 2016            8                   2  \n",
       "133612  September 3, 2009           17                   1  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drugs.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# remove garbage words\n",
    "drugs[\"review\"] = list(map(lambda x : x.replace(\"&#039;\", \"\").replace(\"&quot\",\"\"), drugs.review))\n",
    "\n",
    "# use a smaller subset of the data for quicker processing\n",
    "data = drugs[:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with na values\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change all review to lowercase\n",
    "data[\"review\"] = [review.lower() for review in data.review]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize each word\n",
    "data[\"tk\"] = data.review.apply(lambda x : word_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>drugName</th>\n",
       "      <th>condition</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>usefulCount</th>\n",
       "      <th>rating_categorized</th>\n",
       "      <th>tk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53761</th>\n",
       "      <td>159999</td>\n",
       "      <td>Tamoxifen</td>\n",
       "      <td>Breast Cancer, Prevention</td>\n",
       "      <td>\"i have taken tamoxifen for 5 years. side effe...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>September 13, 2014</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>[``, i, have, taken, tamoxifen, for, 5, years,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53762</th>\n",
       "      <td>140714</td>\n",
       "      <td>Escitalopram</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>\"ive been taking lexapro (escitaploprgram) sin...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>[``, ive, been, taking, lexapro, (, escitaplop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53763</th>\n",
       "      <td>130945</td>\n",
       "      <td>Levonorgestrel</td>\n",
       "      <td>Birth Control</td>\n",
       "      <td>\"im married, 34 years old and i have no kids. ...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>November 15, 2010</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>[``, im, married, ,, 34, years, old, and, i, h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53764</th>\n",
       "      <td>47656</td>\n",
       "      <td>Tapentadol</td>\n",
       "      <td>Pain</td>\n",
       "      <td>\"i was prescribed nucynta for severe neck/shou...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>November 28, 2011</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>[``, i, was, prescribed, nucynta, for, severe,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53765</th>\n",
       "      <td>113712</td>\n",
       "      <td>Arthrotec</td>\n",
       "      <td>Sciatica</td>\n",
       "      <td>\"it works!!!\"</td>\n",
       "      <td>9.0</td>\n",
       "      <td>September 13, 2009</td>\n",
       "      <td>46</td>\n",
       "      <td>2</td>\n",
       "      <td>[``, it, works, !, !, !, '']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id        drugName                  condition  \\\n",
       "53761  159999       Tamoxifen  Breast Cancer, Prevention   \n",
       "53762  140714    Escitalopram                    Anxiety   \n",
       "53763  130945  Levonorgestrel              Birth Control   \n",
       "53764   47656      Tapentadol                       Pain   \n",
       "53765  113712       Arthrotec                   Sciatica   \n",
       "\n",
       "                                                  review  rating  \\\n",
       "53761  \"i have taken tamoxifen for 5 years. side effe...    10.0   \n",
       "53762  \"ive been taking lexapro (escitaploprgram) sin...     9.0   \n",
       "53763  \"im married, 34 years old and i have no kids. ...     8.0   \n",
       "53764  \"i was prescribed nucynta for severe neck/shou...     1.0   \n",
       "53765                                      \"it works!!!\"     9.0   \n",
       "\n",
       "                     date  usefulCount  rating_categorized  \\\n",
       "53761  September 13, 2014           43                   2   \n",
       "53762     October 8, 2016           11                   2   \n",
       "53763   November 15, 2010            7                   2   \n",
       "53764   November 28, 2011           20                   0   \n",
       "53765  September 13, 2009           46                   2   \n",
       "\n",
       "                                                      tk  \n",
       "53761  [``, i, have, taken, tamoxifen, for, 5, years,...  \n",
       "53762  [``, ive, been, taking, lexapro, (, escitaplop...  \n",
       "53763  [``, im, married, ,, 34, years, old, and, i, h...  \n",
       "53764  [``, i, was, prescribed, nucynta, for, severe,...  \n",
       "53765                       [``, it, works, !, !, !, '']  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WordNet POS tags are: NOUN = 'n', ADJ = 's', VERB = 'v', ADV = 'r', ADJ_SAT = 'a'\n",
    "# convert from wordnet tags to lemmatizer tags\n",
    "tag_map = defaultdict(lambda: wn.NOUN)\n",
    "mappings = {\n",
    "        'CD':wn.NOUN, # cardinal number (one, two)                          \n",
    "        'EX':wn.ADV, # existential ‘there’ (there)                      \n",
    "        'IN':wn.ADV, # preposition/sub-conj (of, in, by)   \n",
    "        'JJ':wn.ADJ, # adjective (yellow)                  \n",
    "        'JJR':wn.ADJ, # adj., comparative (bigger)          \n",
    "        'JJS':wn.ADJ, # adj., superlative (wildest)                    \n",
    "        'NN':wn.NOUN, # noun, sing. or mass (llama)          \n",
    "        'NNS':wn.NOUN, # noun, plural (llamas)                  \n",
    "        'NNP':wn.NOUN, # proper noun, sing. (IBM)              \n",
    "        'NNPS':wn.NOUN, # proper noun, plural (Carolinas)\n",
    "        'PDT':wn.ADJ, # predeterminer (all, both)            \n",
    "        'RB':wn.ADV, # adverb (quickly, never)            \n",
    "        'RBR':wn.ADV, # adverb, comparative (faster)        \n",
    "        'RBS':wn.ADV, # adverb, superlative (fastest)     \n",
    "        'RP':wn.ADJ, # particle (up, off)\n",
    "        'VB':wn.VERB, # verb base form (eat)\n",
    "        'VBD':wn.VERB, # verb past tense (ate)\n",
    "        'VBG':wn.VERB, # verb gerund (eating)\n",
    "        'VBN':wn.VERB, # verb past participle (eaten)\n",
    "        'VBP':wn.VERB, # verb non-3sg pres (eat)\n",
    "        'VBZ':wn.VERB, # verb 3sg pres (eats)\n",
    "    }\n",
    "\n",
    "for key in mappings:\n",
    "    tag_map[key] = mappings[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14min 37s, sys: 3.34 s, total: 14min 41s\n",
      "Wall time: 14min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Initialize WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# tag part of speech to each word in every review.\n",
    "#tagger = PerceptronTagger()\n",
    "tagged = pos_tag_sents(data.tk)\n",
    "\n",
    "# remove stopwords and non-alpha words\n",
    "cachedStopWords = stopwords.words(\"english\")\n",
    "tagged = [[word_tag for word_tag in review if (word_tag[0] not in cachedStopWords and word_tag[0].isalpha())] for review in tagged]\n",
    "\n",
    "# lemmatize words\n",
    "lemmatized = [[lemmatizer.lemmatize(word_tag[0], tag_map[word_tag[1]]) for word_tag in review] for review in tagged]\n",
    "\n",
    "# Save lemmatized words in \"text_final\" column\n",
    "data[\"text_final\"] = lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>drugName</th>\n",
       "      <th>condition</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>usefulCount</th>\n",
       "      <th>rating_categorized</th>\n",
       "      <th>tk</th>\n",
       "      <th>text_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>206461</td>\n",
       "      <td>Valsartan</td>\n",
       "      <td>Left Ventricular Dysfunction</td>\n",
       "      <td>\"it has no side effect, i take it in combinati...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>May 20, 2012</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>['``', 'it', 'has', 'no', 'side', 'effect', ',...</td>\n",
       "      <td>['side', 'effect', 'take', 'combination', 'bys...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>95260</td>\n",
       "      <td>Guanfacine</td>\n",
       "      <td>ADHD</td>\n",
       "      <td>\"my son is halfway through his fourth week of ...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>April 27, 2010</td>\n",
       "      <td>192</td>\n",
       "      <td>2</td>\n",
       "      <td>['``', 'my', 'son', 'is', 'halfway', 'through'...</td>\n",
       "      <td>['son', 'halfway', 'fourth', 'week', 'intuniv'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>92703</td>\n",
       "      <td>Lybrel</td>\n",
       "      <td>Birth Control</td>\n",
       "      <td>\"i used to take another oral contraceptive, wh...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>December 14, 2009</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>['``', 'i', 'used', 'to', 'take', 'another', '...</td>\n",
       "      <td>['use', 'take', 'another', 'oral', 'contracept...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>138000</td>\n",
       "      <td>Ortho Evra</td>\n",
       "      <td>Birth Control</td>\n",
       "      <td>\"this is my first time using any form of birth...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>November 3, 2015</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>['``', 'this', 'is', 'my', 'first', 'time', 'u...</td>\n",
       "      <td>['first', 'time', 'use', 'form', 'birth', 'con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>35696</td>\n",
       "      <td>Buprenorphine / naloxone</td>\n",
       "      <td>Opiate Dependence</td>\n",
       "      <td>\"suboxone has completely turned my life around...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>November 27, 2016</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>['``', 'suboxone', 'has', 'completely', 'turne...</td>\n",
       "      <td>['suboxone', 'completely', 'turn', 'life', 'ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213864</th>\n",
       "      <td>53761</td>\n",
       "      <td>159999</td>\n",
       "      <td>Tamoxifen</td>\n",
       "      <td>Breast Cancer, Prevention</td>\n",
       "      <td>\"i have taken tamoxifen for 5 years. side effe...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>September 13, 2014</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>['``', 'i', 'have', 'taken', 'tamoxifen', 'for...</td>\n",
       "      <td>['take', 'tamoxifen', 'year', 'side', 'effect'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213865</th>\n",
       "      <td>53762</td>\n",
       "      <td>140714</td>\n",
       "      <td>Escitalopram</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>\"ive been taking lexapro (escitaploprgram) sin...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>['``', 'ive', 'been', 'taking', 'lexapro', '('...</td>\n",
       "      <td>['ive', 'take', 'lexapro', 'escitaploprgram', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213866</th>\n",
       "      <td>53763</td>\n",
       "      <td>130945</td>\n",
       "      <td>Levonorgestrel</td>\n",
       "      <td>Birth Control</td>\n",
       "      <td>\"im married, 34 years old and i have no kids. ...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>November 15, 2010</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>['``', 'im', 'married', ',', '34', 'years', 'o...</td>\n",
       "      <td>['im', 'marry', 'year', 'old', 'kid', 'take', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213867</th>\n",
       "      <td>53764</td>\n",
       "      <td>47656</td>\n",
       "      <td>Tapentadol</td>\n",
       "      <td>Pain</td>\n",
       "      <td>\"i was prescribed nucynta for severe neck/shou...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>November 28, 2011</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>['``', 'i', 'was', 'prescribed', 'nucynta', 'f...</td>\n",
       "      <td>['prescribe', 'nucynta', 'severe', 'pain', 'ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213868</th>\n",
       "      <td>53765</td>\n",
       "      <td>113712</td>\n",
       "      <td>Arthrotec</td>\n",
       "      <td>Sciatica</td>\n",
       "      <td>\"it works!!!\"</td>\n",
       "      <td>9.0</td>\n",
       "      <td>September 13, 2009</td>\n",
       "      <td>46</td>\n",
       "      <td>2</td>\n",
       "      <td>['``', 'it', 'works', '!', '!', '!', \"''\"]</td>\n",
       "      <td>['work']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>213869 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0      id                  drugName  \\\n",
       "0                0  206461                 Valsartan   \n",
       "1                1   95260                Guanfacine   \n",
       "2                2   92703                    Lybrel   \n",
       "3                3  138000                Ortho Evra   \n",
       "4                4   35696  Buprenorphine / naloxone   \n",
       "...            ...     ...                       ...   \n",
       "213864       53761  159999                 Tamoxifen   \n",
       "213865       53762  140714              Escitalopram   \n",
       "213866       53763  130945            Levonorgestrel   \n",
       "213867       53764   47656                Tapentadol   \n",
       "213868       53765  113712                 Arthrotec   \n",
       "\n",
       "                           condition  \\\n",
       "0       Left Ventricular Dysfunction   \n",
       "1                               ADHD   \n",
       "2                      Birth Control   \n",
       "3                      Birth Control   \n",
       "4                  Opiate Dependence   \n",
       "...                              ...   \n",
       "213864     Breast Cancer, Prevention   \n",
       "213865                       Anxiety   \n",
       "213866                 Birth Control   \n",
       "213867                          Pain   \n",
       "213868                      Sciatica   \n",
       "\n",
       "                                                   review  rating  \\\n",
       "0       \"it has no side effect, i take it in combinati...     9.0   \n",
       "1       \"my son is halfway through his fourth week of ...     8.0   \n",
       "2       \"i used to take another oral contraceptive, wh...     5.0   \n",
       "3       \"this is my first time using any form of birth...     8.0   \n",
       "4       \"suboxone has completely turned my life around...     9.0   \n",
       "...                                                   ...     ...   \n",
       "213864  \"i have taken tamoxifen for 5 years. side effe...    10.0   \n",
       "213865  \"ive been taking lexapro (escitaploprgram) sin...     9.0   \n",
       "213866  \"im married, 34 years old and i have no kids. ...     8.0   \n",
       "213867  \"i was prescribed nucynta for severe neck/shou...     1.0   \n",
       "213868                                      \"it works!!!\"     9.0   \n",
       "\n",
       "                      date  usefulCount  rating_categorized  \\\n",
       "0             May 20, 2012           27                   2   \n",
       "1           April 27, 2010          192                   2   \n",
       "2        December 14, 2009           17                   1   \n",
       "3         November 3, 2015           10                   2   \n",
       "4        November 27, 2016           37                   2   \n",
       "...                    ...          ...                 ...   \n",
       "213864  September 13, 2014           43                   2   \n",
       "213865     October 8, 2016           11                   2   \n",
       "213866   November 15, 2010            7                   2   \n",
       "213867   November 28, 2011           20                   0   \n",
       "213868  September 13, 2009           46                   2   \n",
       "\n",
       "                                                       tk  \\\n",
       "0       ['``', 'it', 'has', 'no', 'side', 'effect', ',...   \n",
       "1       ['``', 'my', 'son', 'is', 'halfway', 'through'...   \n",
       "2       ['``', 'i', 'used', 'to', 'take', 'another', '...   \n",
       "3       ['``', 'this', 'is', 'my', 'first', 'time', 'u...   \n",
       "4       ['``', 'suboxone', 'has', 'completely', 'turne...   \n",
       "...                                                   ...   \n",
       "213864  ['``', 'i', 'have', 'taken', 'tamoxifen', 'for...   \n",
       "213865  ['``', 'ive', 'been', 'taking', 'lexapro', '('...   \n",
       "213866  ['``', 'im', 'married', ',', '34', 'years', 'o...   \n",
       "213867  ['``', 'i', 'was', 'prescribed', 'nucynta', 'f...   \n",
       "213868         ['``', 'it', 'works', '!', '!', '!', \"''\"]   \n",
       "\n",
       "                                               text_final  \n",
       "0       ['side', 'effect', 'take', 'combination', 'bys...  \n",
       "1       ['son', 'halfway', 'fourth', 'week', 'intuniv'...  \n",
       "2       ['use', 'take', 'another', 'oral', 'contracept...  \n",
       "3       ['first', 'time', 'use', 'form', 'birth', 'con...  \n",
       "4       ['suboxone', 'completely', 'turn', 'life', 'ar...  \n",
       "...                                                   ...  \n",
       "213864  ['take', 'tamoxifen', 'year', 'side', 'effect'...  \n",
       "213865  ['ive', 'take', 'lexapro', 'escitaploprgram', ...  \n",
       "213866  ['im', 'marry', 'year', 'old', 'kid', 'take', ...  \n",
       "213867  ['prescribe', 'nucynta', 'severe', 'pain', 'ta...  \n",
       "213868                                           ['work']  \n",
       "\n",
       "[213869 rows x 11 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save processed data\n",
    "data.to_csv(\"data_processed.csv\")\n",
    "data = pd.read_csv(\"data_processed.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets\n",
    "Train_X, Test_X, Train_Y, Test_Y = model_selection.train_test_split(data['text_final'],data['rating_categorized'],test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ecode labels to integer values. Use this if labels are not already integers (ex. 'positive', ''negative', etc.)\n",
    "\n",
    "#Encoder = LabelEncoder()\n",
    "#Train_Y = Encoder.fit_transform(Train_Y)\n",
    "#Test_Y = Encoder.fit_transform(Test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize word list\n",
    "\n",
    "Tfidf_vect = TfidfVectorizer(max_features=5000)\n",
    "Tfidf_vect.fit(data[\"text_final\"])\n",
    "\n",
    "Train_X_Tfidf = Tfidf_vect.transform(Train_X)\n",
    "Test_X_Tfidf = Tfidf_vect.transform(Test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(Tfidf_vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(Train_X_Tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [#\"Nearest Neighbors\", \n",
    "         \"Linear SVM\"] \n",
    "         #\"RBF SVM\", \n",
    "         #\"Gaussian Process\",\n",
    "         #\"Decision Tree\", \n",
    "         #\"Random Forest\"] \n",
    "         #\"Neural Net\", \n",
    "         #\"AdaBoost\",\n",
    "         #\"Multinomial Naive Bayes\"]#, \n",
    "         #\"QDA\"]\n",
    "classifiers = [\n",
    "    #KNeighborsClassifier(30, n_jobs=-1),\n",
    "    BaggingClassifier(SVC(kernel='linear', cache_size=10000, probability=False, class_weight='balanced'), max_samples=1.0 / 10 , n_estimators=10, n_jobs=8, verbose=3)] #SVC(kernel=\"linear\", C=0.025),\n",
    "    #SVC(gamma='scale', C=10),\n",
    "    #GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "    #DecisionTreeClassifier(max_depth=5),\n",
    "    #RandomForestClassifier(max_depth=None, n_estimators=40, max_features=\"auto\", n_jobs=8, verbose=2, warm_start=True)]\n",
    "    #MLPClassifier(alpha=1, max_iter=1000),\n",
    "    #AdaBoostClassifier(),\n",
    "    #naive_bayes.MultinomialNB(alpha=1e-10)]#,\n",
    "    #QuadraticDiscriminantAnalysis()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   2 out of   8 | elapsed:  1.7min remaining:  5.0min\n",
      "[Parallel(n_jobs=8)]: Done   5 out of   8 | elapsed:  1.7min remaining:  1.0min\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:  2.9min remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:  2.9min finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   2 out of   8 | elapsed:  2.5min remaining:  7.4min\n",
      "[Parallel(n_jobs=8)]: Done   5 out of   8 | elapsed:  2.5min remaining:  1.5min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM : Accuracy Score ->  66.693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:  4.3min remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:  4.3min finished\n"
     ]
    }
   ],
   "source": [
    "for name, clf in zip(names, classifiers):\n",
    "    \n",
    "    # fit the training dataset on the classifier\n",
    "    clf.fit(Train_X_Tfidf, Train_Y)\n",
    "    \n",
    "    # predict the labels on validation dataset\n",
    "    predictions = clf.predict(Test_X_Tfidf)\n",
    "    \n",
    "    # Use accuracy_score function to get the accuracy\n",
    "    print(name,\": Accuracy Score -> \",round(accuracy_score(predictions, Test_Y)*100,3))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Linear SVM : Accuracy Score ->  67.138\n",
    "Random Forest : Accuracy Score ->  59.906\n",
    "Multinomial Naive Bayes : Accuracy Score ->  68.448"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'alpha': 9.0}, 0.6446484647959069)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parameter tuning\n",
    "\n",
    "parameters = {'alpha':np.arange(9,20,1e-1)}\n",
    "svc = naive_bayes.MultinomialNB()\n",
    "clf = model_selection.GridSearchCV(svc, parameters)\n",
    "clf.fit(Train_X_Tfidf, Train_Y)\n",
    "clf.best_params_, clf.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4nB4biHTeVmE"
   },
   "source": [
    "Here we start deep learning classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "4dvxbsnWeVmE",
    "outputId": "e655bb4c-1657-466e-c06b-7852429a4551"
   },
   "outputs": [],
   "source": [
    "from fastai.vision import *\n",
    "from fastai.metrics import *\n",
    "from fastai.callbacks.hooks import *\n",
    "from fastai.utils.mem import *\n",
    "from fastai.text import *\n",
    "path = \"/root/\"\n",
    "torch.cuda.empty_cache()\n",
    "!/opt/bin/nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "colab_type": "code",
    "id": "Eu43ToTreVmJ",
    "outputId": "45b3778c-91aa-4935-e197-be95cdb159d3"
   },
   "outputs": [],
   "source": [
    "# Import data. There are two clases of data, one for determining the language model (how to read the words), and the other for classification (into ratings 1-10)\n",
    "\n",
    "data_lm = TextLMDataBunch.from_csv(path, \"train.tsv\", delimiter=\"\\t\", text_cols=\"review\", label_cols=\"rating\", bs=96)\n",
    "data_clas = TextClasDataBunch.from_csv(path, \"train.tsv\", delimiter=\"\\t\", text_cols=\"review\", label_cols=\"rating\", vocab=data_lm.train_ds.vocab, bs=96)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yvNTJV_FeVmO"
   },
   "outputs": [],
   "source": [
    "# Save databunch\n",
    "data_lm.save('data_lm_export.pkl')\n",
    "data_clas.save('data_clas_export.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bBWr2ioDeVmS"
   },
   "outputs": [],
   "source": [
    "# Load Databunch\n",
    "\n",
    "bs = 48\n",
    "data_lm = load_data(path, 'data_lm_export.pkl', bs=bs)\n",
    "data_clas = load_data(path, 'data_clas_export.pkl', bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ViIxHDaVeVmU",
    "outputId": "c7d63794-4749-4491-82af-ac593e82c821"
   },
   "outputs": [],
   "source": [
    "# Setup language model learner using the AWD LSTM model.\n",
    "\n",
    "learn = language_model_learner(data_lm, AWD_LSTM, drop_mult=.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 95
    },
    "colab_type": "code",
    "id": "STjqoerpgtT5",
    "outputId": "be436ff6-2332-41aa-a375-6cee655cca31"
   },
   "outputs": [],
   "source": [
    "#fit the model to the data using the one cycle policy\n",
    "\n",
    "learn.fit_one_cycle(1, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "colab_type": "code",
    "id": "iCXuPaRtoDci",
    "outputId": "3f200a03-efec-4d19-f553-4587ef36112e"
   },
   "outputs": [],
   "source": [
    "# find the losses at different learning rates and plot the curve\n",
    "\n",
    "learn.lr_find();\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "colab_type": "code",
    "id": "Q_aWO_ofsAH9",
    "outputId": "944b3e8d-3020-462f-fc18-4793385b457f"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "zB6rSE9ssC8M",
    "outputId": "e981aecd-afda-4cf0-ac89-8ea70e5d3139"
   },
   "outputs": [],
   "source": [
    "# example prediction using the fitted language model\n",
    "\n",
    "learn.predict(\"it could have been\", n_words=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UWsm8EkqwlaA"
   },
   "outputs": [],
   "source": [
    "# save the trained weights of the model\n",
    "\n",
    "learn.save(\"fit_head\")\n",
    "learn.load(\"fit_head\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j0qfYCh1w4I2"
   },
   "outputs": [],
   "source": [
    "# unfreeze the entire model and train again\n",
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(2, max_lr=slice(1e-2, 1e-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q9aD1TmbxIoy"
   },
   "outputs": [],
   "source": [
    "# save the encoder from the fitted language model\n",
    "learn.save_encoder(\"ft_enc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "DzDNuPYp0ASf",
    "outputId": "638411b9-79d6-4795-9c4e-4e12e22bc60e"
   },
   "outputs": [],
   "source": [
    "# Setup the classification learning model and load the language model encoder\n",
    "\n",
    "learn = text_classifier_learner(data_clas, AWD_LSTM, drop_mult=0.5, metrics = [accuracy, rmse])\n",
    "learn.load_encoder(\"ft_enc\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "TGQ0K2iS0Jc4",
    "outputId": "c0810af8-a877-4a00-de24-a9ed645752f5"
   },
   "outputs": [],
   "source": [
    "# Preview the classification batch. It contains one column for the tokenized reviews and another column for the rating labels\n",
    "\n",
    "data_clas.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 188
    },
    "colab_type": "code",
    "id": "aYJJwDXr3bKW",
    "outputId": "6cb97c10-77e3-4f18-8960-f5f7479ac2a7"
   },
   "outputs": [],
   "source": [
    "# Train model using the fit one cycle policy\n",
    "\n",
    "learn.fit_one_cycle(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Skbmqj1E3gVb"
   },
   "outputs": [],
   "source": [
    "# save these initally trained weight\n",
    "\n",
    "learn.save(\"first_clas\")\n",
    "learn.load(\"first_clas\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m9CWwGrL3mlZ"
   },
   "outputs": [],
   "source": [
    "# freeeze the model excep the last two layers for retraining\n",
    "\n",
    "learn.freeze_to(-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ImYsFMbP3psq"
   },
   "outputs": [],
   "source": [
    "# Plot the learning rate \n",
    "\n",
    "learn.lr_find()\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R1twjwxL3zwE"
   },
   "outputs": [],
   "source": [
    "# Fit partially unfrozen model\n",
    "\n",
    "learn.fit_one_cycle(1, slice(1e-4, 1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CXNDx3gDBdXE"
   },
   "outputs": [],
   "source": [
    "# fit fully unfrozen model\n",
    "\n",
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(3, slice(1e-4, 1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OzyTfC_PCkRy"
   },
   "outputs": [],
   "source": [
    "# Save the final classification weights.\n",
    "\n",
    "learn.save(\"final_clas\")\n",
    "learn.load(\"final_clas\");"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Sentiment Analysis (1).ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "name": "pytorch-gpu.1-4.m50",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m50"
  },
  "instance_type": "ml.t3.2xlarge",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
